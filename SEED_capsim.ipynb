{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d402bb",
   "metadata": {},
   "source": [
    "# Generate captions with GIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from PIL import Image\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/git-large-coco\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/git-large-coco\")\n",
    "\n",
    "\n",
    "# FILEPATHS =  \n",
    "\n",
    "captions = {}\n",
    "for url in FILEPATHS:\n",
    "    image = Image.open(url).convert(\"RGB\")\n",
    "    image_id = url.split('/')[-1]\n",
    "    \n",
    "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "    generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
    "    generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    captions[image_id] = generated_caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947b9d4e",
   "metadata": {},
   "source": [
    "# Measure caption similiarty with SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6996b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 0. Load GT Caption & Recon Caption dict\n",
    "'''\n",
    "gt_caption = {\n",
    "    'IAMGE_ID': 'CAPTION',\n",
    "    ... \n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "# GT_CAPTION_PATH = \n",
    "# RECON_CAPTION_PATH = \n",
    "\n",
    "gt_caption = torch.load(GT_CAPTION_PATH)\n",
    "recon_caption = torch.load(RECON_CAPTION_PATH)\n",
    "\n",
    "\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "cossims = []\n",
    "for gt_cap, subj1_cap in zip(gt_caption.values(), recon_caption.values()):\n",
    "    # 2. Calculate embeddings by calling model.encode()\n",
    "    embeddings = model.encode([gt_cap, subj1_cap])\n",
    "    # 3. Calculate the embedding similarities\n",
    "    similarities = model.similarity(embeddings, embeddings)\n",
    "    cossims.append(similarities[0][1].item())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
